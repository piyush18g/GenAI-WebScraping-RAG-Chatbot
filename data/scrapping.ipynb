{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPBVp6mGS2MxX5xamU9Yti2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Y1ENtgqSDxH","executionInfo":{"status":"ok","timestamp":1762434555414,"user_tz":-330,"elapsed":5029,"user":{"displayName":"Piyush Gupta","userId":"14090413756107321523"}},"outputId":"c91c11e8-7d16-44c3-8bf9-3270afb1d0d0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (2.32.4)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (4.13.5)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests) (2025.10.5)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (2.8)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4) (4.15.0)\n","Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"]}],"source":["pip install requests beautifulsoup4 pandas"]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","def scrape_gsmarena(url):\n","    headers = {\n","        \"User-Agent\": \"Mozilla/5.0\"\n","    }\n","\n","    response = requests.get(url, headers=headers)\n","    soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","    # Phone name\n","    name_element = soup.find(\"h1\", class_=\"specs-phone-name-title\")\n","    name = name_element.text.strip() if name_element else \"N/A\"\n","\n","    specs = {\"name\": name}\n","\n","    # Extract all spec categories\n","    specs_div = soup.find(\"div\", id=\"specs-list\")\n","    if not specs_div:\n","        return specs # Return if no specs-list div found\n","\n","    current_category = \"General Specs\"\n","    for child in specs_div.children:\n","        if child.name == 'h2':\n","            current_category = child.text.strip()\n","        elif child.name == 'table':\n","            for row in child.find_all(\"tr\"):\n","                key_element = row.find(\"td\", class_=\"ttl\")\n","                value_element = row.find(\"td\", class_=\"nfo\")\n","\n","                if key_element and value_element:\n","                    key = key_element.text.strip()\n","                    value = value_element.text.strip()\n","                    # Clean up the category name\n","                    cleaned_category = current_category.replace(' ', '_').replace('/', '_').replace('.', '').replace('(', '').replace(')', '')\n","                    specs[f\"{cleaned_category}_{key}\"] = value\n","\n","    return specs\n","\n","\n","#TEST SCRAPER\n","url = \"https://www.gsmarena.com/samsung_galaxy_s23-12024.php\"\n","data = scrape_gsmarena(url)\n","\n","for k, v in data.items():\n","    print(k, \":\", v)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqOB4nwuSRzh","executionInfo":{"status":"ok","timestamp":1762434690763,"user_tz":-330,"elapsed":717,"user":{"displayName":"Piyush Gupta","userId":"14090413756107321523"}},"outputId":"8b494b89-82ad-4a20-e891-c1f7f52596d0"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["name : Samsung Galaxy S23 Ultra\n","General_Specs_Technology : GSM / CDMA / HSPA / EVDO / LTE / 5G\n","General_Specs_2G bands : GSM 850 / 900 / 1800 / 1900\n","General_Specs_ : Samsung DeX, Samsung Wireless DeX (desktop experience support)\r\n","Ultra Wideband (UWB) support\n","General_Specs_3G bands : HSDPA 850 / 900 / 1700(AWS) / 1900 / 2100\n","General_Specs_4G bands : 1, 2, 3, 4, 5, 7, 8, 12, 13, 17, 18, 19, 20, 25, 26, 28, 32, 38, 39, 40, 41, 66 - International\n","General_Specs_5G bands : 1, 2, 3, 5, 7, 8, 12, 20, 25, 28, 38, 40, 41, 66, 75, 77, 78 SA/NSA/Sub6 - International\n","General_Specs_Speed : HSPA, LTE (up to 7CA), 5G\n","General_Specs_Announced : 2023, February 01\n","General_Specs_Status : Available. Released 2023, February 17\n","General_Specs_Dimensions : 163.4 x 78.1 x 8.9 mm (6.43 x 3.07 x 0.35 in)\n","General_Specs_Weight : 234 g (8.25 oz)\n","General_Specs_Build : Glass front (Gorilla Glass Victus 2), glass back (Gorilla Glass Victus 2), aluminum frame\n","General_Specs_SIM : · Nano-SIM + eSIM· Nano-SIM + Nano-SIM + eSIM (max 2 at a time)\n","General_Specs_Type : Li-Ion 5000 mAh\n","General_Specs_Size : 6.8 inches, 114.7 cm2 (~89.9% screen-to-body ratio)\n","General_Specs_Resolution : 1440 x 3088 pixels, 19.3:9 ratio (~500 ppi density)\n","General_Specs_Protection : Corning Gorilla Glass Victus 2\n","General_Specs_OS : Android 13, up to 4 major Android upgrades, One UI 8\n","General_Specs_Chipset : Qualcomm SM8550-AC Snapdragon 8 Gen 2 (4 nm)\n","General_Specs_CPU : Octa-core (1x3.36 GHz Cortex-X3 & 2x2.8 GHz Cortex-A715 & 2x2.8 GHz Cortex-A710 & 3x2.0 GHz Cortex-A510)\n","General_Specs_GPU : Adreno 740\n","General_Specs_Card slot : No\n","General_Specs_Internal : 256GB 8GB RAM, 256GB 12GB RAM, 512GB 12GB RAM, 1TB 12GB RAM\n","General_Specs_Quad : 200 MP, f/1.7, 24mm (wide), 1/1.3\", 0.6µm, multi-directional PDAF, OIS\r\n","10 MP, f/2.4, 70mm (telephoto), 1/3.52\", 1.12µm, PDAF, OIS, 3x optical zoom\r\n","10 MP, f/4.9, 230mm (periscope telephoto), 1/3.52\", 1.12µm, PDAF, OIS, 10x optical zoom\r\n","12 MP, f/2.2, 13mm, 120˚ (ultrawide), 1/2.55\", 1.4µm, dual pixel PDAF, Super Steady video\n","General_Specs_Features : HDR, HDR10+\n","General_Specs_Video : 4K@30/60fps, 1080p@30fps\n","General_Specs_Single : 12 MP, f/2.2, 26mm (wide), 1/3.2\", 1.12µm, dual pixel PDAF\n","General_Specs_Loudspeaker : -25.6 LUFS (Very good)\n","General_Specs_3.5mm jack : No\n","General_Specs_WLAN : Wi-Fi 802.11 a/b/g/n/ac/6e, tri-band, Wi-Fi Direct\n","General_Specs_Bluetooth : 5.3, A2DP, LE\n","General_Specs_Positioning : GPS, GALILEO, GLONASS, BDS, QZSS\n","General_Specs_NFC : Yes\n","General_Specs_Radio : No\n","General_Specs_USB : USB Type-C 3.2, OTG\n","General_Specs_Sensors : Fingerprint (under display, ultrasonic), accelerometer, gyro, proximity, compass, barometer\n","General_Specs_Charging : 45W wired, PD3.0, 65% in 30 min\r\n","15W wireless (Qi)\r\n","4.5W reverse wireless\n","General_Specs_Colors : Phantom Black, Green, Cream, Lavender, Graphite, Sky Blue, Lime, Red, BMW M Edition\n","General_Specs_Models : SM-S918B, SM-S918B/DS, SM-S918U, SM-S918U1, SM-S918W, SM-S918N, SM-S9180, SM-S918E, SM-S918E/DS\n","General_Specs_SAR : 1.12 W/kg (head)     0.92 W/kg (body)\n","General_Specs_SAR EU : 0.96 W/kg (head)     1.40 W/kg (body)\n","General_Specs_Price : $ 451.62 / C$ 562.75 / £ 458.00 / € 427.40 / ₹ 78,399\n","General_Specs_Performance : AnTuTu: 1241531 (v9)\r\n","GeekBench: 4927 (v5.1)\r\n","3DMark: 3790 (Wild Life Extreme)\n","General_Specs_Display : 1274 nits max brightness (measured)\n","General_Specs_Camera : Photo / Video\n","General_Specs_Battery : Active use score 13:24h\n","General_Specs_Battery (old) : Endurance rating 126h\n"]}]},{"cell_type":"code","source":["import json\n","\n","with open(\"s23.json\", \"w\") as f:\n","    json.dump(data, f, indent=4)"],"metadata":{"id":"0BwR-EGgTDAW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["phones = {\n","    \"s23\": \"https://www.gsmarena.com/samsung_galaxy_s23-12024.php\",\n","    \"iphone_15\": \"https://www.gsmarena.com/apple_iphone_15-12532.php\",\n","    \"iqoo_z7\": \"https://www.gsmarena.com/vivo_iqoo_z7-12165.php\"\n","}\n","\n","all_data = []\n","\n","for name, link in phones.items():\n","    all_data.append(scrape_gsmarena(link))\n","\n","# Save entire dataset\n","json.dump(all_data, open(\"phones.json\", \"w\"), indent=4)\n"],"metadata":{"id":"CDPunC1VTJQP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import json\n","\n","def scrape_gadgets360(url):\n","    headers = {\n","        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n","    }\n","\n","    response = requests.get(url, headers=headers)\n","    if response.status_code != 200:\n","        print(f\"Failed to load page. Status code: {response.status_code}\")\n","        print(f\"Response text (first 500 chars): {response.text[:500]}\")\n","        return None\n","\n","    soup = BeautifulSoup(response.text, \"html.parser\")\n","    data = {}\n","\n","    # ✅ Phone Name\n","    try:\n","        data[\"name\"] = soup.find(\"h1\", class_=\"product-title\").text.strip()\n","    except:\n","        data[\"name\"] = None\n","\n","    # ✅ Price in India\n","    try:\n","        price_block = soup.find(\"div\", class_=\"price\")\n","        data[\"price\"] = price_block.text.strip()\n","    except:\n","        data[\"price\"] = None\n","\n","    # ✅ Highlights (Key Specs)\n","    highlights = []\n","    try:\n","        hl_block = soup.find(\"div\", class_=\"specs-keypoints\")\n","        for li in hl_block.find_all(\"li\"):\n","            highlights.append(li.text.strip())\n","    except:\n","        pass\n","    data[\"highlights\"] = highlights\n","\n","    # ✅ Full Specification Table\n","    specs = {}\n","    try:\n","        tables = soup.find_all(\"table\", class_=\"table-hover\")\n","        for table in tables:\n","            category = table.find_previous(\"h2\").text.strip()\n","            specs[category] = {}\n","\n","            for row in table.find_all(\"tr\"):\n","                cols = row.find_all(\"td\")\n","                if len(cols) == 2:\n","                    key = cols[0].text.strip()\n","                    value = cols[1].text.strip()\n","                    specs[category][key] = value\n","    except:\n","        pass\n","\n","    data[\"specifications\"] = specs\n","    return data\n","\n","\n","# ✅ TEST SCRAPER\n","url = \"https://gadgets360.com/mobiles/samsung-galaxy-s23-price-in-india-113953\"\n","phone_data = scrape_gadgets360(url)\n","\n","print(json.dumps(phone_data, indent=4))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D9Bnhc0AUhpY","executionInfo":{"status":"ok","timestamp":1762435302996,"user_tz":-330,"elapsed":177,"user":{"displayName":"Piyush Gupta","userId":"14090413756107321523"}},"outputId":"332c7fb1-56bf-4ae4-afc3-cc7847a50d9a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Failed to load page. Status code: 403\n","Response text (first 500 chars): <HTML><HEAD>\n","<TITLE>Access Denied</TITLE>\n","</HEAD><BODY>\n","<H1>Access Denied</H1>\n"," \n","You don't have permission to access \"http&#58;&#47;&#47;gadgets360&#46;com&#47;mobiles&#47;samsung&#45;galaxy&#45;s23&#45;price&#45;in&#45;india&#45;113953\" on this server.<P>\n","Reference&#32;&#35;18&#46;ce06d217&#46;1762435302&#46;6f3ae40b\n","<P>https&#58;&#47;&#47;errors&#46;edgesuite&#46;net&#47;18&#46;ce06d217&#46;1762435302&#46;6f3ae40b</P>\n","</BODY>\n","</HTML>\n","\n","null\n"]}]},{"cell_type":"code","source":["pip install selenium webdriver-manager bs4"],"metadata":{"id":"E5V4SIABWUvI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762714080583,"user_tz":-330,"elapsed":8831,"user":{"displayName":"Piyush Gupta","userId":"14090413756107321523"}},"outputId":"cf6c2bb4-352e-4d83-c02b-23fa071a2195"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting selenium\n","  Downloading selenium-4.38.0-py3-none-any.whl.metadata (7.5 kB)\n","Collecting webdriver-manager\n","  Downloading webdriver_manager-4.0.2-py2.py3-none-any.whl.metadata (12 kB)\n","Collecting bs4\n","  Downloading bs4-0.0.2-py2.py3-none-any.whl.metadata (411 bytes)\n","Requirement already satisfied: urllib3<3.0,>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (2.5.0)\n","Collecting trio<1.0,>=0.31.0 (from selenium)\n","  Downloading trio-0.32.0-py3-none-any.whl.metadata (8.5 kB)\n","Collecting trio-websocket<1.0,>=0.12.2 (from selenium)\n","  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n","Requirement already satisfied: certifi>=2025.10.5 in /usr/local/lib/python3.12/dist-packages (from selenium) (2025.10.5)\n","Requirement already satisfied: typing_extensions<5.0,>=4.15.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (4.15.0)\n","Requirement already satisfied: websocket-client<2.0,>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from selenium) (1.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (2.32.4)\n","Requirement already satisfied: python-dotenv in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (1.2.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from webdriver-manager) (25.0)\n","Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.12/dist-packages (from bs4) (4.13.5)\n","Requirement already satisfied: attrs>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (25.4.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (2.4.0)\n","Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (3.11)\n","Collecting outcome (from trio<1.0,>=0.31.0->selenium)\n","  Downloading outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n","Requirement already satisfied: sniffio>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from trio<1.0,>=0.31.0->selenium) (1.3.1)\n","Collecting wsproto>=0.14 (from trio-websocket<1.0,>=0.12.2->selenium)\n","  Downloading wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n","Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.12/dist-packages (from urllib3[socks]<3.0,>=2.5.0->selenium) (1.7.1)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4->bs4) (2.8)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->webdriver-manager) (3.4.4)\n","Requirement already satisfied: h11<1,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from wsproto>=0.14->trio-websocket<1.0,>=0.12.2->selenium) (0.16.0)\n","Downloading selenium-4.38.0-py3-none-any.whl (9.7 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading webdriver_manager-4.0.2-py2.py3-none-any.whl (27 kB)\n","Downloading bs4-0.0.2-py2.py3-none-any.whl (1.2 kB)\n","Downloading trio-0.32.0-py3-none-any.whl (512 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m512.0/512.0 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n","Downloading outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n","Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Installing collected packages: wsproto, outcome, webdriver-manager, trio, bs4, trio-websocket, selenium\n","Successfully installed bs4-0.0.2 outcome-1.3.0.post0 selenium-4.38.0 trio-0.32.0 trio-websocket-0.12.2 webdriver-manager-4.0.2 wsproto-1.2.0\n"]}]},{"cell_type":"code","source":["import os\n","import requests\n","from selenium import webdriver\n","from selenium.webdriver.chrome.service import Service\n","from webdriver_manager.chrome import ChromeDriverManager\n","from bs4 import BeautifulSoup\n","import time\n","import json\n","\n","# Install Google Chrome stable and its dependencies\n","!apt-get update\n","!apt-get install -y libvulkan1 # Install missing dependency\n","!wget -q https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n","!dpkg -i google-chrome-stable_current_amd64.deb\n","!apt-get install -y --fix-missing\n","\n","# Set the path to the Chrome binary\n","CHROME_BIN_PATH = '/usr/bin/google-chrome'\n","\n","def scrape_flipkart_selenium(url):\n","    options = webdriver.ChromeOptions()\n","    options.add_argument(\"--headless\")\n","    options.add_argument(\"--no-sandbox\")\n","    options.add_argument(\"--disable-dev-shm-usage\")\n","    options.add_argument(\"--disable-gpu\")\n","    options.add_argument(\"--window-size=1920,1080\")\n","    options.add_argument(\"--disable-blink-features=AutomationControlled\")\n","    options.add_argument(\"user-agent=Mozilla/5.0\")\n","    options.binary_location = CHROME_BIN_PATH\n","\n","    # Use ChromeDriverManager to automatically install and manage ChromeDriver\n","    # It will find a compatible ChromeDriver for the installed Google Chrome stable\n","    service = Service(ChromeDriverManager().install())\n","\n","    driver = webdriver.Chrome(\n","        service=service,\n","        options=options\n","    )\n","\n","    driver.get(url)\n","    time.sleep(10) # Increased sleep time for page to load to ensure content loads\n","\n","    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n","    driver.quit()\n","\n","    product_data = {}\n","\n","    # Product Name - Updated selector based on user provided HTML\n","    name_element = soup.select_one(\"span.VU-ZEz\") # Using the specific class provided by the user\n","    product_data[\"name\"] = name_element.text.strip() if name_element else \"N/A\"\n","\n","    # Price (current, original, discount)\n","    current_price_element = soup.select_one(\".Nx9bqj.CxhGGd\")\n","    product_data[\"current_price\"] = current_price_element.text.strip() if current_price_element else \"N/A\"\n","\n","    # Original price - Using raw string for selector to avoid SyntaxWarning\n","    original_price_element = soup.select_one(r\".yRaY8j.A6\\+E6v\")\n","    product_data[\"original_price\"] = original_price_element.text.strip() if original_price_element else \"N/A\"\n","\n","    discount_element = soup.select_one(\".UkUFwK.WW8yVX\")\n","    product_data[\"discount\"] = discount_element.text.strip() if discount_element else \"N/A\"\n","\n","    # Highlights / Key Features\n","    highlights = []\n","    # Refined selectors for highlights/key specs lists - targeting common Flipkart patterns\n","    highlight_sections = soup.select(\"div._1mXcCf ul li, div._2l0sN7 ul li, div._3FN5M2 ul li, div._2cM9iY ul li\")\n","    for item in highlight_sections:\n","        highlights.append(item.text.strip())\n","    product_data[\"highlights\"] = highlights if highlights else \"N/A\"\n","\n","    return product_data\n","\n","\n","url = \"https://www.flipkart.com/redmi-13-5g-black-diamond-128-gb/p/itmbf96c9b15ce5e\" # Using a working URL example\n","product_details = scrape_flipkart_selenium(url)\n","print(json.dumps(product_details, indent=4))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7f7jri5NEpyu","executionInfo":{"status":"ok","timestamp":1762701751176,"user_tz":-330,"elapsed":45260,"user":{"displayName":"Piyush Gupta","userId":"14090413756107321523"}},"outputId":"54f2ee56-e486-432c-8dd5-1064bfac579a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 https://dl.google.com/linux/chrome/deb stable InRelease\n","\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Waiting for headers] [C\r                                                                               \rHit:2 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [Connected to cloud.r-pr\r                                                                               \rHit:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","\r0% [Waiting for headers] [Connected to r2u.stat.illinois.edu (192.17.190.167)] \r                                                                               \rHit:4 https://cli.github.com/packages stable InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Connected to developer.download\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","\r0% [Waiting for headers] [Waiting for headers] [Connected to ppa.launchpadconte\r                                                                               \rHit:6 http://archive.ubuntu.com/ubuntu jammy InRelease\n","Hit:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Hit:8 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libvulkan1 is already the newest version (1.3.204.1-2).\n","0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n","(Reading database ... 125824 files and directories currently installed.)\n","Preparing to unpack google-chrome-stable_current_amd64.deb ...\n","Unpacking google-chrome-stable (142.0.7444.134-1) over (142.0.7444.134-1) ...\n","Setting up google-chrome-stable (142.0.7444.134-1) ...\n","Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n","{\n","    \"name\": \"REDMI 13 5G (Hawaiian Blue, 128 GB)\\u00a0\\u00a0(8 GB RAM)\",\n","    \"current_price\": \"\\u20b912,345\",\n","    \"original_price\": \"\\u20b919,999\",\n","    \"discount\": \"38% off\",\n","    \"highlights\": \"N/A\"\n","}\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"M2Zc25K3MQN0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","\n","def scrape_croma(url):\n","    headers = {\n","        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n","    }\n","\n","    response = requests.get(url, headers=headers)\n","    if response.status_code != 200:\n","        return {\"error\": \"Failed to fetch page\"}\n","\n","    soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","    data = {}\n","\n","    # ✅ Product Name\n","    title = soup.select_one(\"h1.pdp__title\")\n","    data[\"name\"] = title.text.strip() if title else None\n","\n","    # ✅ Price\n","    price = soup.select_one(\".pdp__priceText\")\n","    data[\"price\"] = price.text.strip() if price else None\n","\n","    # ✅ Old Price + Discount\n","    old_price = soup.select_one(\".pdp__mrpPrice\")\n","    discount = soup.select_one(\".pdp__discount\")\n","\n","    data[\"old_price\"] = old_price.text.strip() if old_price else None\n","    data[\"discount\"] = discount.text.strip() if discount else None\n","\n","    # ✅ Highlights / Features\n","    highlights = []\n","    highlight_items = soup.select(\".key-feature-item li\")\n","    for item in highlight_items:\n","        highlights.append(item.text.strip())\n","\n","    data[\"highlights\"] = highlights if highlights else None\n","\n","    # ✅ Availability\n","    availability = soup.select_one(\".pdp__delivery-details\")\n","    data[\"availability\"] = availability.text.strip() if availability else \"In stock\"\n","\n","    return data\n","\n","\n","# ✅ Example usage\n","url = \"https://www.croma.com/samsung-galaxy-s24-5g-256gb/p/275944\"  # Replace with any Croma mobile link\n","result = scrape_croma(url)\n","\n","print(result)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YpAdHKAZEtcz","executionInfo":{"status":"ok","timestamp":1762700663360,"user_tz":-330,"elapsed":331,"user":{"displayName":"Piyush Gupta","userId":"14090413756107321523"}},"outputId":"00eaf13f-97b3-4440-b786-29699f266800"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'error': 'Failed to fetch page'}\n"]}]},{"cell_type":"code","source":["import os\n","from selenium import webdriver\n","from selenium.webdriver.chrome.service import Service\n","from webdriver_manager.chrome import ChromeDriverManager\n","from selenium.webdriver.chrome.options import Options\n","from bs4 import BeautifulSoup\n","import time\n","import json\n","\n","# Install Google Chrome stable and its dependencies\n","# These commands should ideally run once per session, but including them in the cell\n","# ensures they are executed if the runtime resets.\n","!apt-get update\n","!apt-get install -y libvulkan1 # Install missing dependency\n","!wget -q https://dl.google.com/linux/direct/google-chrome-stable_current_amd64.deb\n","!dpkg -i google-chrome-stable_current_amd64.deb\n","!apt-get install -y --fix-missing\n","\n","# Set the path to the Chrome binary\n","CHROME_BIN_PATH = '/usr/bin/google-chrome'\n","\n","options = Options()\n","options.add_argument(\"--headless=new\")\n","options.add_argument(\"--no-sandbox\")\n","options.add_argument(\"--disable-dev-shm-usage\")\n","options.add_argument(\"--disable-gpu\")\n","options.add_argument(\"--window-size=1920,1080\")\n","options.add_argument(\"--disable-blink-features=AutomationControlled\")\n","options.add_argument(\"user-agent=Mozilla/5.0\")\n","options.binary_location = CHROME_BIN_PATH\n","\n","# Initialize the WebDriver once outside the loop\n","service = Service(ChromeDriverManager().install())\n","driver = webdriver.Chrome(\n","    service=service,\n","    options=options\n",")\n","\n","all_phones_data = []\n","base_url = \"https://www.flipkart.com/search?q=mobile+phones\"\n","max_pages_to_scrape = 10 # To get at least 200 results (Flipkart typically shows 24 items per page)\n","\n","print(f\"Starting to scrape up to {max_pages_to_scrape} pages from Flipkart...\")\n","\n","for page_num in range(1, max_pages_to_scrape + 1):\n","    current_url = f\"{base_url}&page={page_num}\"\n","    print(f\"Scraping page {page_num}: {current_url}\")\n","\n","    driver.get(current_url)\n","    time.sleep(5) # Increased sleep time for pages to fully load and dynamic content to render\n","\n","    soup = BeautifulSoup(driver.page_source, \"html.parser\")\n","\n","    product_cards = soup.find_all(\"div\", class_=\"_75nlfW\")\n","\n","    if not product_cards:\n","        print(f\"No product cards found on page {page_num}. Ending pagination.\")\n","        break\n","\n","    for card in product_cards:\n","        product_data = {}\n","\n","        # Product Name\n","        name_element = card.find(\"div\", class_=\"KzDlHZ\")\n","        product_data[\"name\"] = name_element.text.strip() if name_element else \"N/A\"\n","\n","        # Current Price\n","        current_price_element = card.find(\"div\", class_=\"Nx9bqj\")\n","        product_data[\"current_price\"] = current_price_element.text.strip() if current_price_element else \"N/A\"\n","\n","        # Original Price\n","        original_price_element = card.find(\"div\", class_=\"yRaY8j\")\n","        product_data[\"original_price\"] = original_price_element.text.strip() if original_price_element else \"N/A\"\n","\n","        # Discount\n","        discount_element = card.find(\"div\", class_=\"UkUFwK\")\n","        product_data[\"discount\"] = discount_element.text.strip() if discount_element else \"N/A\"\n","\n","        # Ratings\n","        rating_element = card.find(\"div\", class_=\"XQDdHH\")\n","        product_data[\"rating\"] = rating_element.text.strip() if rating_element else \"N/A\"\n","\n","        # Number of Ratings and Reviews\n","        rating_review_element = card.find(\"span\", class_=\"Wphh3N\")\n","        if rating_review_element:\n","            text = rating_review_element.text.strip()\n","            # The text might be like '23,292 Ratings & 1,123 Reviews'\n","            parts = text.split('&')\n","            product_data[\"total_ratings\"] = parts[0].replace('Ratings', '').strip() if len(parts) > 0 else \"N/A\"\n","            product_data[\"total_reviews\"] = parts[1].replace('Reviews', '').strip() if len(parts) > 1 else \"N/A\"\n","        else:\n","            product_data[\"total_ratings\"] = \"N/A\"\n","            product_data[\"total_reviews\"] = \"N/A\"\n","\n","        # Key Features (Highlights)\n","        features = []\n","        feature_list = card.find(\"ul\", class_=\"G4BRas\")\n","        if feature_list:\n","            for li in feature_list.find_all(\"li\"):\n","                features.append(li.text.strip())\n","        product_data[\"features\"] = features if features else []\n","\n","        all_phones_data.append(product_data)\n","\n","    print(f\"Scraped {len(product_cards)} phones from page {page_num}. Total phones collected so far: {len(all_phones_data)}\")\n","\n","# Quit the driver after all pages have been scraped\n","driver.quit()\n","\n","# Overwrite the 'phones' variable with the collected data\n","phones = all_phones_data\n","\n","print(f\"Finished scraping. Total {len(phones)} phones collected.\")\n","# print(json.dumps(phones, indent=4)) # Uncomment to print the full JSON output"],"metadata":{"id":"-3TmOc2gJZcd","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1762715945793,"user_tz":-330,"elapsed":100990,"user":{"displayName":"Piyush Gupta","userId":"14090413756107321523"}},"outputId":"7e0bd8c3-8d09-4263-dc5e-b71c36e01e57"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\r0% [Working]\r            \rHit:1 https://dl.google.com/linux/chrome/deb stable InRelease\n","\r0% [Connecting to archive.ubuntu.com (91.189.91.82)] [Connecting to security.ub\r                                                                               \rHit:2 https://cli.github.com/packages stable InRelease\n","\r0% [Waiting for headers] [Connecting to security.ubuntu.com (185.125.190.81)] [\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu jammy InRelease\n","\r0% [Connecting to security.ubuntu.com (185.125.190.81)] [Connecting to cloud.r-\r                                                                               \rHit:4 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n","Hit:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n","Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n","Hit:7 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n","Hit:8 http://security.ubuntu.com/ubuntu jammy-security InRelease\n","Hit:9 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n","Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n","Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n","Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n","Reading package lists... Done\n","W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libvulkan1 is already the newest version (1.3.204.1-2).\n","0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n","(Reading database ... 125401 files and directories currently installed.)\n","Preparing to unpack google-chrome-stable_current_amd64.deb ...\n","Unpacking google-chrome-stable (142.0.7444.134-1) over (142.0.7444.134-1) ...\n","Setting up google-chrome-stable (142.0.7444.134-1) ...\n","Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n","Processing triggers for man-db (2.10.2-1) ...\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","0 upgraded, 0 newly installed, 0 to remove and 46 not upgraded.\n","Starting to scrape up to 10 pages from Flipkart...\n","Scraping page 1: https://www.flipkart.com/search?q=mobile+phones&page=1\n","Scraped 24 phones from page 1. Total phones collected so far: 24\n","Scraping page 2: https://www.flipkart.com/search?q=mobile+phones&page=2\n","Scraped 24 phones from page 2. Total phones collected so far: 48\n","Scraping page 3: https://www.flipkart.com/search?q=mobile+phones&page=3\n","Scraped 24 phones from page 3. Total phones collected so far: 72\n","Scraping page 4: https://www.flipkart.com/search?q=mobile+phones&page=4\n","Scraped 24 phones from page 4. Total phones collected so far: 96\n","Scraping page 5: https://www.flipkart.com/search?q=mobile+phones&page=5\n","Scraped 24 phones from page 5. Total phones collected so far: 120\n","Scraping page 6: https://www.flipkart.com/search?q=mobile+phones&page=6\n","Scraped 24 phones from page 6. Total phones collected so far: 144\n","Scraping page 7: https://www.flipkart.com/search?q=mobile+phones&page=7\n","Scraped 24 phones from page 7. Total phones collected so far: 168\n","Scraping page 8: https://www.flipkart.com/search?q=mobile+phones&page=8\n","Scraped 24 phones from page 8. Total phones collected so far: 192\n","Scraping page 9: https://www.flipkart.com/search?q=mobile+phones&page=9\n","Scraped 24 phones from page 9. Total phones collected so far: 216\n","Scraping page 10: https://www.flipkart.com/search?q=mobile+phones&page=10\n","Scraped 24 phones from page 10. Total phones collected so far: 240\n","Finished scraping. Total 240 phones collected.\n"]}]},{"cell_type":"code","metadata":{"id":"24f3c184","executionInfo":{"status":"ok","timestamp":1762716075185,"user_tz":-330,"elapsed":75,"user":{"displayName":"Piyush Gupta","userId":"14090413756107321523"}}},"source":["def chunk_mobile_data(data):\n","    model = data.get(\"name\", \"Unknown Model\") # Changed from 'model' to 'name' to match Flipkart data\n","    brand = data.get(\"brand\", \"\") # 'brand' is not a direct key in Flipkart data, will likely be empty unless parsed from name\n","\n","    chunks = []\n","\n","    def add_chunk(key, value):\n","        if value and value != \"\":\n","            chunks.append(f\"{model} — {key}: {value}\")\n","\n","    # ✅ Simple fields (GSMArena-like keys, mostly not directly in Flipkart data)\n","    # These fields will likely remain empty/None as they are not top-level keys in the Flipkart scraped data\n","    # They would need to be extracted from the 'features' list if desired.\n","    simple_fields = {\n","        \"Brand\": brand,\n","        \"Current Price\": data.get(\"current_price\"),\n","        \"Original Price\": data.get(\"original_price\"),\n","        \"Discount\": data.get(\"discount\"),\n","        \"Rating\": data.get(\"rating\"),\n","        \"Total Ratings\": data.get(\"total_ratings\"),\n","        \"Total Reviews\": data.get(\"total_reviews\"),\n","        \"Display\": data.get(\"display\"), # Not directly available, would need parsing from 'features'\n","        \"Processor\": data.get(\"processor\"), # Not directly available, would need parsing from 'features'\n","        \"Battery\": data.get(\"battery\"), # Not directly available, would need parsing from 'features'\n","        \"Rear Camera\": data.get(\"rear_camera\"), # Not directly available, would need parsing from 'features'\n","        \"Front Camera\": data.get(\"front_camera\"), # Not directly available, would need parsing from 'features'\n","        \"Charging\": data.get(\"charging\"), # Not directly available, would need parsing from 'features'\n","        \"Dimensions\": data.get(\"dimensions\"), # Not directly available, would need parsing from 'features'\n","        \"Weight\": data.get(\"weight\"), # Not directly available, would need parsing from 'features'\n","        \"OS\": data.get(\"os\"), # Not directly available, would need parsing from 'features'\n","        \"Network Bands\": data.get(\"network_bands\"), # Not directly available, would need parsing from 'features'\n","        \"Build\": data.get(\"build\"), # Not directly available, would need parsing from 'features'\n","        \"Extras\": data.get(\"extras\") # Not directly available, would need parsing from 'features'\n","    }\n","\n","    for key, value in simple_fields.items():\n","        add_chunk(key, value)\n","\n","    # ✅ Price (using the Flipkart 'current_price' as a general 'price' for consistency if available)\n","    if \"current_price\" in data:\n","        add_chunk(\"Price\", data[\"current_price\"])\n","\n","    # ✅ Features list (Flipkart)\n","    features = data.get(\"features\", [])\n","    for f in features:\n","        f_clean = f.replace(\"|\", \",\").strip()\n","        chunks.append(f\"{model} — Feature: {f_clean}\") # Changed key to 'Feature' for clarity\n","\n","    return chunks"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"0b22a8e3","executionInfo":{"status":"ok","timestamp":1762716080078,"user_tz":-330,"elapsed":389,"user":{"displayName":"Piyush Gupta","userId":"14090413756107321523"}}},"source":["import json\n","\n","all_phone_chunks = []\n","for phone_data in phones:\n","    chunks = chunk_mobile_data(phone_data)\n","    all_phone_chunks.extend(chunks)\n","\n","with open(\"flipkart_phones_chunks.json\", \"w\") as f:\n","    json.dump(all_phone_chunks, f, indent=4)"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"a399ec58","executionInfo":{"status":"ok","timestamp":1762716083612,"user_tz":-330,"elapsed":9,"user":{"displayName":"Piyush Gupta","userId":"14090413756107321523"}}},"source":["import json\n","\n","with open(\"flipkart_phones.json\", \"w\") as f:\n","    json.dump(phones, f, indent=4)"],"execution_count":18,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"sQjJntD397rt"},"execution_count":null,"outputs":[]}]}
